{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32ebd7a",
   "metadata": {},
   "source": [
    "## Security Analysis on LSH-based BTPS\n",
    "- Seunghun Paik, Sunpill Kim and Jae Hong Seo\n",
    "- BMVC 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e62d3",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Implementation of three LSH-based BTPs (GRP/URP-IoM [1], ABH [2])\n",
    "- Implementation of the proposed attack\n",
    "- Comparison with previous two attacks (Dong et al. [3], Ghammam et al. [4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c40b9",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "- pytorch\n",
    "- matplotlib\n",
    "- cvxopt (for Ghammam et al. [2])\n",
    "\n",
    "For benchmarking of LSH-basted BTPs, three representative datasets (LFW, CFP-FP, and AgeDB are required!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660ac72",
   "metadata": {},
   "source": [
    "## 0. Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Device\n",
    "device = \"cpu\"                  ### Put your device if GPU is available\n",
    "\n",
    "### Path for Benchmark Sets\n",
    "test_dir = \"your dir\"\n",
    "\n",
    "### Path for Backbone\n",
    "bb_dir = \"your dir\"\n",
    "\n",
    "### Path for NbNet\n",
    "nb_dir = \"your dir\"\n",
    "\n",
    "### Path for Demo Images\n",
    "demo_dir = \"./demo\"\n",
    "\n",
    "from fr_utils import get_backbone\n",
    "from nbnet import get_nbnet\n",
    "backbone = get_backbone(\"r50\", bb_dir, device)\n",
    "nbnet = get_nbnet(nb_dir, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b70f8",
   "metadata": {},
   "source": [
    "## 1. Implementation Results of LSH-based BTPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter Preset\n",
    "from BTPs import GRP, URP, ABH\n",
    "\n",
    "grp = GRP(300, 16, 512, device)\n",
    "urp = URP(600, 100, 2, 512, device)\n",
    "abh = ABH(50, 60, 2, 22, 512, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07592ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Benchmarking\n",
    "from fr_utils.verification import load_bin, test\n",
    "lfw = load_bin(test_dir + \"/lfw.bin\", (112,112))\n",
    "cfp = load_bin(test_dir + \"/cfp_fp.bin\", (112,112))\n",
    "age = load_bin(test_dir + \"/agedb_30.bin\", (112,112))\n",
    "\n",
    "### Batch Size\n",
    "batch_size = 128     ### Modify this value in accordance with your experimental environment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e808ce5",
   "metadata": {},
   "source": [
    "### GRP-IoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bcc83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Testing on LFW: \", test(lfw, backbone, batch_size, device))\n",
    "print(\"Testing on CFP-FP: \", test(cfp, batch_size, device))\n",
    "print(\"Testing on AgeDB: \", test(age, batch_size, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e905261",
   "metadata": {},
   "source": [
    "### URP-IoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing on LFW: \", test(lfw, backbone, batch_size, device))\n",
    "print(\"Testing on CFP-FP: \", test(cfp, batch_size, device))\n",
    "print(\"Testing on AgeDB: \", test(age, batch_size, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a237da8",
   "metadata": {},
   "source": [
    "### ABH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f401b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing on LFW: \", test(lfw, backbone, batch_size, device))\n",
    "print(\"Testing on CFP-FP: \", test(cfp, batch_size, device))\n",
    "print(\"Testing on AgeDB: \", test(age, batch_size, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029400e8",
   "metadata": {},
   "source": [
    "## 2. Implementation Result of Proposed Attack\n",
    "\n",
    "We will show the effectiveness of our attack via DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91799bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Demo images in the paper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### FOR ABH\n",
    "img1 = plt.imread(demo_dir + \"/img1.jpg\")\n",
    "img2 = plt.imread(demo_dir + \"/img2.jpg\")\n",
    "### FOR GRP\n",
    "img3 = plt.imread(demo_dir + \"/img3.jpg\")\n",
    "### FOR URP\n",
    "img4 = plt.imread(demo_dir + \"/img4.jpg\")\n",
    "img5 = plt.imread(demo_dir + \"/img5.jpg\")\n",
    "\n",
    "for i in range(1,6):\n",
    "    plt.subplot(1, 5, i)\n",
    "    plt.imshow(globals()[\"img\" + str(i)])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6889c",
   "metadata": {},
   "source": [
    "### Attack Pipeline\n",
    "\n",
    "After enrollment, the attack can be done in the following procedure:\n",
    "\n",
    "- Step 1. FInd the pre-image of the given template\n",
    "- Step 2. Using NbNet, recover the image from the pre-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b81baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature extraction\n",
    "### function for pre-processing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def preproc_img(img):\n",
    "    # Normalization \n",
    "    img = torch.tensor(img) / 127.5 - 1\n",
    "    # HWC -> CHW\n",
    "    img = img.permute(2,0,1)\n",
    "    # Reshape\n",
    "    img = F.interpolate(img.unsqueeze(0), size=(112,112))\n",
    "    return img\n",
    "\n",
    "### Tensor to Image\n",
    "ten2img = lambda ten: (ten.detach().cpu().numpy().transpose(1,2,0) + 1) / 2\n",
    "\n",
    "### Preparation\n",
    "feat1 = backbone(preproc_img(img1))\n",
    "feat2 = backbone(preproc_img(img2))\n",
    "feat3 = backbone(preproc_img(img3))\n",
    "feat4 = backbone(preproc_img(img4))\n",
    "feat5 = backbone(preproc_img(img5))\n",
    "\n",
    "### Enrollment\n",
    "tmp1 = abh.hashing(feat1)\n",
    "tmp2 = abh.hashing(feat2)\n",
    "tmp3 = grp.hashing(feat3)\n",
    "tmp4 = urp.hashing(feat4)\n",
    "tmp5 = urp.hashing(feat5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93314ba",
   "metadata": {},
   "source": [
    "### ABH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import attack_abh_efficient \n",
    "\n",
    "feat1_r = attack_abh_efficient(abh, tmp1)\n",
    "feat2_r = attack_abh_efficient(abh, tmp2)\n",
    "\n",
    "img1_r = nbnet(F.normalize(feat1_r))\n",
    "img2_r = nbnet(F.normalize(feat2_r))\n",
    "\n",
    "feat1_rr = backbone(F.interpolate(img1_r, (112,112)))\n",
    "feat2_rr = backbone(F.interpolate(img2_r, (112,112)))\n",
    "\n",
    "angle1 = F.cosine_similarity(feat1, feat1_rr).acos() * 180 / torch.pi\n",
    "angle2 = F.cosine_similarity(feat2, feat2_rr).acos() * 180 / torch.pi\n",
    "\n",
    "\n",
    "### Plotting Imgs\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Enrolled\")\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img2)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Recovered\")\n",
    "plt.imshow(ten2img(img1_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(ten2img(img2_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Angles Between Them. img1: {angle1.item()}, img2: {angle2.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461831e",
   "metadata": {},
   "source": [
    "### GRP-IoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import attack_grp_efficient\n",
    "\n",
    "feat3_r = attack_grp_efficient(grp, tmp3)\n",
    "img3_r = nbnet(F.normalize(feat3_r))\n",
    "feat3_rr = backbone(F.interpolate(img3_r, (112,112)))\n",
    "angle3 = F.cosine_similarity(feat3, feat3_rr).acos() * 180 / torch.pi\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Enrolled\")\n",
    "plt.imshow(img3)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Recovered\")\n",
    "plt.imshow(ten2img(img3_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "print(\"Angle Between Them: \", angle3.item())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27f11d",
   "metadata": {},
   "source": [
    "### URP-IoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81178c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from attacks import attack_LSH_anom, loss_fn_urp\n",
    "feat4_r = attack_LSH_anom(tmp4, loss_fn_urp, urp.w)\n",
    "feat5_r = attack_LSH_anom(tmp5, loss_fn_urp, urp.w)\n",
    "\n",
    "img4_r = nbnet(F.normalize(feat4_r))\n",
    "img5_r = nbnet(F.normalize(feat5_r))\n",
    "\n",
    "feat4_rr = backbone(F.interpolate(img4_r, (112,112)))\n",
    "feat5_rr = backbone(F.interpolate(img5_r, (112,112)))\n",
    "\n",
    "angle4 = F.cosine_similarity(feat4, feat4_rr).acos() * 180 / torch.pi\n",
    "angle5 = F.cosine_similarity(feat5, feat5_rr).acos() * 180 / torch.pi\n",
    "\n",
    "if (angle4 > 90):\n",
    "    feat4_r = -feat4_r\n",
    "    \n",
    "if (angle5 > 90):\n",
    "    feat5_r = -feat5_r\n",
    "\n",
    "\n",
    "img4_r = nbnet(F.normalize(feat4_r))\n",
    "img5_r = nbnet(F.normalize(feat5_r))\n",
    "\n",
    "feat4_rr = backbone(F.interpolate(img4_r, (112,112)))\n",
    "feat5_rr = backbone(F.interpolate(img5_r, (112,112)))\n",
    "\n",
    "angle4 = F.cosine_similarity(feat4, feat4_rr).acos() * 180 / torch.pi\n",
    "angle5 = F.cosine_similarity(feat5, feat5_rr).acos() * 180 / torch.pi\n",
    "\n",
    "    \n",
    "    \n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Enrolled\")\n",
    "plt.imshow(img4)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img5)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Recovered\")\n",
    "plt.imshow(ten2img(img4_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(ten2img(img5_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Angles Between Them. img4: {angle4.item()}, img5: {angle5.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f47cab",
   "metadata": {},
   "source": [
    "## 3. Comparison with Previous Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e6868",
   "metadata": {},
   "source": [
    "### Dong et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a3cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import attack_GA\n",
    "import numpy as np\n",
    "\n",
    "feat1_ga = attack_GA(abh, tmp1)\n",
    "feat2_ga = attack_GA(abh, tmp2)\n",
    "feat3_ga = attack_GA(grp, tmp3)\n",
    "feat4_ga = attack_GA(urp, tmp4)\n",
    "\n",
    "img1_ga = nbnet(F.normalize(feat1_ga))\n",
    "img2_ga = nbnet(F.normalize(feat2_ga))\n",
    "img3_ga = nbnet(F.normalize(feat3_ga))\n",
    "img4_ga = nbnet(F.normalize(feat4_ga))\n",
    "\n",
    "for i in range(1, 13):\n",
    "    if (i-1)//4 == 0:\n",
    "        img = globals()[\"img\" + str(i)]\n",
    "    \n",
    "    elif (i-1)//4 == 1:\n",
    "        img = globals()[\"img\" + str(i-4) + \"_ga\"]\n",
    "    \n",
    "    else:\n",
    "        img = globals()[\"img\" + str(i-8) + \"_r\"]\n",
    "    \n",
    "    plt.subplot(3, 4, i)\n",
    "    if isinstance(img, np.ndarray):\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(ten2img(img[0]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e521455",
   "metadata": {},
   "source": [
    "### Ghammam et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks import attack_urp_efficient\n",
    "\n",
    "feat5_gham = attack_urp_efficient(urp, tmp5)\n",
    "img5_gham = nbnet(F.normalize(feat5_gham))\n",
    "\n",
    "feat5_rgham = backbone(F.interpolate(img5_gham, (112,112)))\n",
    "angle5_gham = F.cosine_similarity(feat5, feat5_rgham).acos() * 180 / torch.pi\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Enrolled\")\n",
    "plt.imshow(img5)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Recovered by \\n Ghammam et al.\")\n",
    "plt.imshow(ten2img(img5_gham[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(r\"Recovered by Ours.\")\n",
    "plt.imshow(ten2img(img5_r[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Angle Between Them (Ghammam): \", angle5_gham.item())\n",
    "print(\"Angle Between Them (Ours): \", angle5.item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
